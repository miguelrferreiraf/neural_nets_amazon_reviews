{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis_reviews.ipynb","provenance":[],"authorship_tag":"ABX9TyOecCaeLrVasBotxdgA43pE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"tQrp_x1IDwiz","executionInfo":{"status":"ok","timestamp":1656871621684,"user_tz":180,"elapsed":3259,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}}},"outputs":[],"source":["'''Libraries importation'''\n","\n","'''DON'T YOU FORGET TYHAT THE CSV DATA YOU GOT IS HEAVY AND YOU HADN'T TIME ENOUGH TO UPLOAD IT.'''\n","\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import re\n","import keras\n","from keras import Model\n","from tensorflow.keras.layers import Flatten,LSTM,Dense,Flatten,Embedding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from keras_preprocessing.text import Tokenizer\n","from keras.initializers import glorot_uniform\n","from sklearn import model_selection"]},{"cell_type":"code","source":["'''Here is established the text our model will train upon. It's a CSV archive, for its\n","easier to work on:'''\n","\n","#Read in data\n","with open('train.csv', 'r') as file:\n","  text = file.readlines()\n"],"metadata":{"id":"PBMJBHfTg7p6","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1656871905662,"user_tz":180,"elapsed":290,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}},"outputId":"1d5dcd78-c0d9-4f92-e64d-01acf8706da3"},"execution_count":12,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d3c76cb437b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Read in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://drive.google.com/file/d/1t_11EHwBLJYROYoDruVnNhZSzianVIy1/view?usp=sharing'"]}]},{"cell_type":"code","source":["'''The dataframe creation is useful for selet'''\n","\n","#create empty dataframe\n","x_train = pd.DataFrame()"],"metadata":{"id":"LIGvAdZ-hRUB","executionInfo":{"status":"ok","timestamp":1656871709434,"user_tz":180,"elapsed":299,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["'''We must turn the words of the csv list into strings for it may be more useble.\n","We can use a trick to make a loop by using for command. The loop may find out the words\n","and convert it to strings automatically.'''\n","\n","# fill in dataframe\n","word=[]\n","label=[]\n","for n in data:\n","  n=n.split()\n","  label.append(1) if n[0] ==\"__label__2\" else label.append(0)\n","  word.append(\" \".join(n[1:]))\n","x_train['consumer_review'] = word\n","x_train['polarity_label'] = label\n","\n","#view dataframe\n","x_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"b6UAcotjjUd6","executionInfo":{"status":"ok","timestamp":1656871747237,"user_tz":180,"elapsed":331,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}},"outputId":"a948896c-ab37-47ee-87ff-0b9ca41d439c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       consumer_review  polarity_label\n","0    html><html><head><meta name=\"google\" content=\"...               0\n","1                                                                    0\n","2                                                                    0\n","3    nonce=\"TL0Jwu4etgNdXd2Esey0yQ\"><link rel=\"styl...               0\n","4                                                                    0\n","..                                                 ...             ...\n","753                                                                  0\n","754                                                                  0\n","755                                                                  0\n","756                                                                  0\n","757                                       window=this;               0\n","\n","[758 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-8f76b4b2-4143-4bbb-9c22-a24f15c6b55c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>consumer_review</th>\n","      <th>polarity_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>html&gt;&lt;html&gt;&lt;head&gt;&lt;meta name=\"google\" content=\"...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nonce=\"TL0Jwu4etgNdXd2Esey0yQ\"&gt;&lt;link rel=\"styl...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>753</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>754</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>755</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>756</th>\n","      <td></td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>757</th>\n","      <td>window=this;</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>758 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f76b4b2-4143-4bbb-9c22-a24f15c6b55c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f76b4b2-4143-4bbb-9c22-a24f15c6b55c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f76b4b2-4143-4bbb-9c22-a24f15c6b55c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["'''This project uses basic step-by-step of an IA project. As almost IA project. it has a \n","specific part for data loading and data preparation. Here we prepare the data using the basic\n","line of command train_test_split. We're goig to separate 20% of the data for training the model.'''\n","\n","#use only 20% of data to avoid overloading your system. You can reduce or increase this number according to your convenience.\n","\n","_, x_set,_, y_set = model_selection.train_test_split(x_train['consumer_review'], \n","                                                     x_train['polarity_label'],\n","                                                     test_size=0.02)\n","                                "],"metadata":{"id":"DJ7AMs-UmTvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''We must turn the data readable for the computer. So, we must emove capitalizations and ponctuations that\n","may disturb computer comprehension.'''\n","\n","#data cleaning function\n","def data_prep(in_tex):\n","  # Remove punctuations and numbers\n","  out_tex = re.sub('[^a-zA-Z]', ' ', in_tex)\n","  # Convert upper case to lower case\n","  out_tex=\"\".join(list(map(lambda x:x.lower(),out_tex)))\n","  # Remove single character\n","  out_tex= re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', out_tex)\n","  return out_tex"],"metadata":{"id":"_FMpSBLuoKPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''New list with new clean data'''\n","\n","#create new list with clean data\n","text_set=[]\n","for reviews in list(x_set):\n","  text_set.append(data_prep(reviews))"],"metadata":{"id":"osZ3vGNFoNiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train= pd.DataFrame()\n","x_train['consumer_review'] = text_set\n","x_train['polarity_label'] = list(y_set)"],"metadata":{"id":"w93OMMb1oTCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#split data into 70% train and 30% test\n","x_train, x_test, y_train, y_test = \\\n","model_selection.train_test_split(x_train['consumer_review'],\n","x_train['polarity_label'],\n","\n","test_size=0.30)"],"metadata":{"id":"eNshy0EzoVFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''We are going to use a tokenizer. For this so we must convert data in array list.'''\n","\n","#convert to array\n","x_train=np.array(x_train.values.tolist())\n","x_test=np.array(x_test.values.tolist())\n","y_train=np.array(y_train.values.tolist())\n","y_test=np.array(y_test.values.tolist())\n"],"metadata":{"id":"A3f9ZPMWoZDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Tokenizer application.'''\n","\n","#tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","word_index=tokenizer.word_index\n","total_size = len(word_index)+1\n","print(total_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSoUGCk-odLS","executionInfo":{"status":"ok","timestamp":1656542584497,"user_tz":180,"elapsed":569,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}},"outputId":"f53da664-bd27-45bf-cc0b-d22ae5ee83e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["841\n"]}]},{"cell_type":"code","source":["'''In order to make the model processing easier, we convert the text to input format.'''\n","\n","#text to sequence\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_test = tokenizer.texts_to_sequences(x_test)"],"metadata":{"id":"v8nYd89dokEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#add padding to ensure the same length\n","max_length = 100\n","x_train = pad_sequences(x_train, padding='post', maxlen=max_length)\n","x_test = pad_sequences(x_test, padding='post', maxlen=max_length)"],"metadata":{"id":"O_1WMNVgomh9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Now, with the data completely worked in order to turn it more workable for the model, \n","wqe finnaly create the model and fit it upon our data. For this work, we must use a neural \n","network model with Keras embedding layer, wich fits more or this specifial job. Neural Networks \n","may not to be useful or as efficient as linear regression or random forests in predicting \n","numerical behavior in closed sections, but it's further more powerful on abstract works as\n","playing chess, text analysis, voice recognition and even in music composition. It must be \n","perfect for a sentiment analysis algorithm.'''\n","\n","#Create Model\n","model = Sequential()\n","model.add(Embedding(total_size, 20, input_length=max_length))\n","model.add(LSTM(32,dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))"],"metadata":{"id":"k0E9Agubos08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Compilation'''\n","\n","#compile\n","model.compile(optimizer='adam', loss='binary_crossentropy',\n","metrics=['acc'])\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x99917sbovOj","executionInfo":{"status":"ok","timestamp":1656542659854,"user_tz":180,"elapsed":496,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}},"outputId":"a10cb7a9-5279-4080-f88d-cea6aa1142c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 100, 20)           16820     \n","                                                                 \n"," lstm (LSTM)                 (None, 32)                6784      \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 23,637\n","Trainable params: 23,637\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["'''Model fitting and '''\n","\n","model.fit(x_train, y_train, batch_size=128, epochs=5,\n","verbose=1, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozOQ-f-LoyAz","executionInfo":{"status":"ok","timestamp":1656542685629,"user_tz":180,"elapsed":9361,"user":{"displayName":"Miguel Ferreira","userId":"17610755308831863052"}},"outputId":"eb670fc0-f8b8-48e6-9c33-fee73c991d7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1/1 [==============================] - 7s 7s/step - loss: 0.7059 - acc: 0.0606 - val_loss: 0.6987 - val_acc: 0.1333\n","Epoch 2/5\n","1/1 [==============================] - 0s 362ms/step - loss: 0.6981 - acc: 0.1212 - val_loss: 0.6910 - val_acc: 1.0000\n","Epoch 3/5\n","1/1 [==============================] - 0s 264ms/step - loss: 0.6904 - acc: 0.9091 - val_loss: 0.6835 - val_acc: 1.0000\n","Epoch 4/5\n","1/1 [==============================] - 0s 383ms/step - loss: 0.6831 - acc: 1.0000 - val_loss: 0.6760 - val_acc: 1.0000\n","Epoch 5/5\n","1/1 [==============================] - 0s 381ms/step - loss: 0.6756 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcdb0afb5d0>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["'''Now we save the model'''\n","\n","model.save(\"model.h5\")"],"metadata":{"id":"x2KQVoC7o5pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''This code line above can e used to reload the pretrained model. Surely you need to train it harder for \n","a better result. For a better training, we can add more layers at our LSTM model or make them denser.'''\n","\n","model = keras.models.load_model(\"model.h5\")\n","\n","'''This is it.'''"],"metadata":{"id":"249zWQMgo7uD"},"execution_count":null,"outputs":[]}]}